{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carvana Image segmentation my solution with a pre-trained encoder'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Carvana Image segmentation my solution with a pre-trained encoder'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import  tqdm\n",
    "import GPUtil as GPU\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "import cv2\n",
    "from torchvision.transforms import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask=pd.read_csv('train_masks.csv')\n",
    "metadata=pd.read_csv('metadata.csv')\n",
    "submission=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images= os.listdir('train_hq')\n",
    "test_images= os.listdir('test_hq')\n",
    "train_masks= os.listdir('train_masks')\n",
    "train_path= [os.path.join('train_hq',i) for i in os.listdir('train_hq')]\n",
    "test_path=[os.path.join('test_hq',i) for i in os.listdir('test_hq')]\n",
    "mask_path=[os.path.join('train_masks',i) for i in os.listdir('train_masks')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6254.0\n"
     ]
    }
   ],
   "source": [
    "print(len(test_images)/16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 318 training images, and 6254 test images. No of training images>test images so that might create a problem. Valdimir approaches this by pseudo labelling, see what it is later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def plot_image_and_mask(train_images):\n",
    "    #plot the train_images\n",
    "    figure,axis=plt.subplots(len(train_images),2,figsize=(2*10,10*len(train_images)))\n",
    "    for i in range(len(train_images)):\n",
    "        id=train_images[i]\n",
    "        image_path=os.path.join('train',id)\n",
    "        mask_path=os.path.join('train_masks',id)[:-4]+'_mask.gif'\n",
    "        print(np.array(Image.open(image_path)).shape)\n",
    "        axis[i][0].imshow(Image.open(image_path))\n",
    "        axis[i][1].imshow(Image.open(mask_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_image_and_mask(train_images[50:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shutil craetes symbolic link to the directories where the files are copied. When we create folds, the data does not disappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test code to create the folds \n",
    "# from pathlib import Path\n",
    "# import shutil\n",
    "# local_data_path=Path('.').absolute()/'folds'\n",
    "# local_data_path.mkdir(exist_ok=True)\n",
    "# train_path= Path('.').absolute()/'train_hq/'\n",
    "# #train_path= Path('.').absolute()/'train/'\n",
    "# mask_path=Path('.').absolute()/'train_masks'\n",
    "# train_file_list=train_images\n",
    "# folds=pd.read_csv('folds_csv.csv')\n",
    "# num_folds=folds.fold.nunique()\n",
    "# #the cars are at sixteen angles \n",
    "# angles=['0'+ str(i) for i in range (1,10)]+ [str(i) for i in range(10,17)]\n",
    "# #now create the folder containing the folds \n",
    "# for fold in range(num_folds):\n",
    "#     #create the folder correspoonding to number of folds\n",
    "#     (local_data_path / str(fold) / 'train' / 'images').mkdir(exist_ok=True, parents=True)\n",
    "#     (local_data_path / str(fold) / 'train' / 'masks').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "#     (local_data_path / str(fold) / 'val' / 'images').mkdir(exist_ok=True, parents=True)\n",
    "#     (local_data_path / str(fold) / 'val' / 'masks').mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# for i in tqdm(folds.index):\n",
    "#     car_id=folds.loc[i,'id']\n",
    "#     fold=folds.loc[i,'fold']\n",
    "#     #copy the 16 images to fold directory \n",
    "#     #this is considered as a val this time \n",
    "#     for angle in angles:\n",
    "#         old_image_path = train_path / (car_id + '_' + angle + '.jpg')\n",
    "\n",
    "#         new_image_path = local_data_path / str(fold) / 'val' / 'images' / (car_id + '_' + angle + '.jpg')\n",
    "#         shutil.copy(str(old_image_path), str(new_image_path))\n",
    "\n",
    "#         old_mask_path = mask_path / (car_id + '_' + angle + '_mask.gif')\n",
    "#         new_mask_path = local_data_path / str(fold) / 'val' / 'masks' / (car_id + '_' + angle + '_mask.gif')\n",
    "#         shutil.copy(str(old_mask_path), str(new_mask_path))\n",
    "        \n",
    "#     #for all the other folds this will be considered as a  training image\n",
    "#     for t_fold in range(num_folds):\n",
    "#             if t_fold == fold:\n",
    "#                 continue\n",
    "\n",
    "#             for angle in angles:\n",
    "#                 old_image_path = train_path / (car_id + '_' + angle + '.jpg')\n",
    "\n",
    "#                 new_image_path = local_data_path / str(t_fold) / 'train' / 'images' / (car_id + '_' + angle + '.jpg')\n",
    "#                 shutil.copy(str(old_image_path), str(new_image_path))\n",
    "\n",
    "#                 old_mask_path = mask_path / (car_id + '_' + angle + '_mask.gif')\n",
    "#                 new_mask_path = local_data_path / str(t_fold) / 'train' / 'masks' / (car_id + '_' + angle + '_mask.gif')\n",
    "#                 shutil.copy(str(old_mask_path), str(new_mask_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take care of the modelling now. The original implementation used unet 11 with a pre-trained vgg-11 encoder, which is what we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelling\n",
    "from torch import nn \n",
    "from torch.nn import functional as F\n",
    "import torch \n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vladimir uses the Unet architecture for semantic segmentation. The modifications to the net are taurusunet where a pre-trained encoder is used for the segmentation. Let's try to do the modelling here and try to understand the input dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle multiple gpus in the jupyter notebook \n",
    "device=torch.device(\"cuda:1\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "if device.type=='cuda':\n",
    "    gpu_id=[]\n",
    "    GPUs = GPU.getGPUs()\n",
    "    for i in range(len(GPUs)):\n",
    "        gpu = GPUs[i]\n",
    "        if gpu.memoryFree>5000:\n",
    "            gpu_id.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "\n",
    "def concat(xs):\n",
    "    return torch.cat(xs, 1)\n",
    "\n",
    "\n",
    "class Conv3BN(nn.Module):\n",
    "    def __init__(self, in_: int, out: int, bn=False):\n",
    "        super().__init__()\n",
    "        self.conv = conv3x3(in_, out)\n",
    "        self.bn = nn.BatchNorm2d(out) if bn else None\n",
    "        self.activation = nn.SELU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            ConvRelu(in_channels, middle_channels),\n",
    "            nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_: int, out: int):\n",
    "        super().__init__()\n",
    "        self.conv = conv3x3(in_, out)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UNet11(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_filters=32):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.encoder = models.vgg11(pretrained=True).features\n",
    "        self.relu = self.encoder[1]\n",
    "        self.conv1 = self.encoder[0]\n",
    "        self.conv2 = self.encoder[3]\n",
    "        self.conv3s = self.encoder[6]\n",
    "        self.conv3 = self.encoder[8]\n",
    "        self.conv4s = self.encoder[11]\n",
    "        self.conv4 = self.encoder[13]\n",
    "        self.conv5s = self.encoder[16]\n",
    "        self.conv5 = self.encoder[18]\n",
    "\n",
    "        self.center = DecoderBlock(num_filters * 8 * 2, num_filters * 8 * 2, num_filters * 8)\n",
    "        self.dec5 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 8)\n",
    "        self.dec4 = DecoderBlock(num_filters * (16 + 8), num_filters * 8 * 2, num_filters * 4)\n",
    "        self.dec3 = DecoderBlock(num_filters * (8 + 4), num_filters * 4 * 2, num_filters * 2)\n",
    "        self.dec2 = DecoderBlock(num_filters * (4 + 2), num_filters * 2 * 2, num_filters)\n",
    "        self.dec1 = ConvRelu(num_filters * (2 + 1), num_filters)\n",
    "\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.relu(self.conv1(x))\n",
    "        conv2 = self.relu(self.conv2(self.pool(conv1)))\n",
    "        conv3s = self.relu(self.conv3s(self.pool(conv2)))\n",
    "        conv3 = self.relu(self.conv3(conv3s))\n",
    "        conv4s = self.relu(self.conv4s(self.pool(conv3)))\n",
    "        conv4 = self.relu(self.conv4(conv4s))\n",
    "        conv5s = self.relu(self.conv5s(self.pool(conv4)))\n",
    "        conv5 = self.relu(self.conv5(conv5s))\n",
    "\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n",
    "        return F.sigmoid(self.final(dec1))\n",
    "\n",
    "    \n",
    "#writing the dice based loss weights for the neural network \n",
    "\n",
    "class Loss:\n",
    "    #init script for the loss\n",
    "    def __init__(self, dice_weight=1):\n",
    "        self.nll_loss = nn.BCELoss()\n",
    "        self.dice_weight = dice_weight\n",
    "\n",
    "    #call called if parameters are given to the network \n",
    "    def __call__(self, outputs, targets):\n",
    "        loss = self.nll_loss(outputs, targets)\n",
    "        if self.dice_weight:\n",
    "            eps = 1e-15\n",
    "            dice_target = (targets == 1).float()\n",
    "            dice_output = outputs\n",
    "            intersection = (dice_output * dice_target).sum()\n",
    "            union = dice_output.sum() + dice_target.sum() + eps\n",
    "\n",
    "            loss -= torch.log(2 * intersection / union)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "#create a dataloader for the carvana dataset\n",
    "train_images= os.listdir('train_hq')\n",
    "test_images= os.listdir('test_hq')\n",
    "train_masks= os.listdir('train_masks')\n",
    "train_path= [os.path.join('train_hq',i) for i in os.listdir('train_hq')]\n",
    "test_path=[os.path.join('test_hq',i) for i in os.listdir('test_hq')]\n",
    "mask_path=[os.path.join('train_masks',i) for i in os.listdir('train_masks')]\n",
    "\n",
    "'''returns the padded image'''\n",
    "#writing the image loader function \n",
    "def load_image(path):\n",
    "    img=cv2.imread(path)\n",
    "    img = cv2.copyMakeBorder(img, 0, 0, 1, 1, cv2.BORDER_REFLECT_101)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img=cv2.resize(img,(img.shape[1]//2,img.shape[0]//2))\n",
    "    return img.astype(np.uint8)\n",
    "'''returns the mask'''\n",
    "def load_mask(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            if '.gif' in str(path):\n",
    "                img = (np.asarray(img) > 0)\n",
    "            else:\n",
    "                img = (np.asarray(img) > 255 * 0.5)\n",
    "            img = cv2.copyMakeBorder(img.astype(np.uint8), 0, 0, 1, 1, cv2.BORDER_REFLECT_101)\n",
    "           # img=cv2.resize(img,(img.shape[1]//2,img.shape[0]//2))\n",
    "            return img.astype(np.float32)\n",
    "        \n",
    "img_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "        \n",
    "'''since we are feeding the images to pretrained vgg11, we need to normalize the weights\n",
    "https://pytorch.org/docs/stable/torchvision/models.html\n",
    "make a transformation pipeline for input images in the carvana dataset'''\n",
    "#our dataloader should also handle the image augmentation \n",
    "#inherit the Dataset\n",
    "\n",
    "class CarvanaDataset(Dataset):\n",
    "    def __init__(self, root: Path, to_augment=False):\n",
    "        # TODO This potentially may lead to bug.\n",
    "        self.image_paths = sorted(root.joinpath('images').glob('*.jpg'))\n",
    "        self.mask_paths = sorted(root.joinpath('masks').glob('*'))\n",
    "        self.to_augment = to_augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img=load_image(str(self.image_paths[idx]))\n",
    "        mask = load_mask(str(self.mask_paths[idx]))\n",
    "#\n",
    "\n",
    "        return img_transform(img), torch.from_numpy(np.expand_dims(mask, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2.0434, 2.0434, 2.0434,  ..., 2.0434, 2.0434, 2.0434],\n",
       "          [2.0434, 2.0434, 2.0434,  ..., 2.0434, 2.0434, 2.0434],\n",
       "          [2.0434, 2.0434, 2.0434,  ..., 2.0434, 2.0434, 2.0434],\n",
       "          ...,\n",
       "          [0.9303, 0.9303, 0.9303,  ..., 0.9132, 0.9132, 0.9132],\n",
       "          [0.9303, 0.9303, 0.9303,  ..., 0.9132, 0.8961, 0.9132],\n",
       "          [0.9132, 0.9132, 0.9132,  ..., 0.9132, 0.9132, 0.9132]],\n",
       " \n",
       "         [[2.2185, 2.2185, 2.2185,  ..., 2.2185, 2.2185, 2.2185],\n",
       "          [2.2185, 2.2185, 2.2185,  ..., 2.2185, 2.2185, 2.2185],\n",
       "          [2.2185, 2.2185, 2.2185,  ..., 2.2185, 2.2185, 2.2185],\n",
       "          ...,\n",
       "          [1.1506, 1.1506, 1.1506,  ..., 1.0980, 1.0980, 1.0980],\n",
       "          [1.1506, 1.1506, 1.1506,  ..., 1.0980, 1.0805, 1.0980],\n",
       "          [1.1331, 1.1331, 1.1331,  ..., 1.0980, 1.0980, 1.0980]],\n",
       " \n",
       "         [[2.3960, 2.3960, 2.3960,  ..., 2.4308, 2.4308, 2.4308],\n",
       "          [2.3960, 2.3960, 2.3960,  ..., 2.4308, 2.4308, 2.4308],\n",
       "          [2.3960, 2.3960, 2.3960,  ..., 2.4308, 2.4308, 2.4308],\n",
       "          ...,\n",
       "          [1.3851, 1.3851, 1.3851,  ..., 1.2980, 1.2980, 1.2980],\n",
       "          [1.3851, 1.3851, 1.3851,  ..., 1.2980, 1.2805, 1.2980],\n",
       "          [1.3677, 1.3677, 1.3677,  ..., 1.2980, 1.2980, 1.2980]]]),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_data_path=Path('.').absolute()/'folds'\n",
    "a=CarvanaDataset(local_data_path/str(2)/'train')\n",
    "fold_path=sorted((local_data_path/str(2)/'train').joinpath('images').glob('*.jpg'))\n",
    "fold_path[0]\n",
    "a[0]\n",
    "\n",
    "#load_image('/data2/6666/rajat.modi/practice/Carvana/carvana/CarvanaSegmentation/folds/2/train/images/00087a6bd4dc_01.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_loader(ds_root: Path, to_augment=False, shuffle=False):\n",
    "    return DataLoader(\n",
    "        dataset=CarvanaDataset(ds_root, to_augment=to_augment),\n",
    "        shuffle=shuffle,\n",
    "        num_workers=1,\n",
    "        batch_size=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "gpu_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################VALIDATION FUNCTION#################\n",
    "batch_size=4\n",
    "def get_dice_score(y_true,y_pred):\n",
    "    epsilon=1e-15\n",
    "    intersection= (y_true*y_pred).sum()\n",
    "    union=y_true.sum()+y_pred.sum()+epsilon\n",
    "    return 2*(intersection/union)\n",
    "\n",
    "def validation(model,criterion,valid_loader):\n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    dice=[]\n",
    "    tq=tqdm(total=len(valid_loader)*batch_size)\n",
    "    for inputs,target in valid_loader:\n",
    "        target=target.to(device)\n",
    "        output=model(inputs).to(device)\n",
    "        loss=criterion(output,target)\n",
    "        current_batch_size=inputs.size(0)\n",
    "        losses.append(loss.item())\n",
    "        tq.update(current_batch_size)\n",
    "        dice.append(get_dice_score(target,(output>0.5).float()).item())\n",
    "    \n",
    "    #take a mean of the loss and dice score here\n",
    "    tq.close()\n",
    "    valid_loss=np.mean(losses)\n",
    "    valid_dice=np.mean(dice)\n",
    "    print('Valid loss: {:.5f}, dice: {:.5f}'.format(valid_loss, valid_dice))\n",
    "    metrics = {'valid_loss': valid_loss, 'dice_loss': valid_dice}\n",
    "    return metrics\n",
    "\n",
    "# dice=validation(model,criterion,val_loader)\n",
    "# print(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for cyclic learning rate \n",
    "def cyclic_lr(epoch, init_lr=1e-4, num_epochs_per_cycle=5, cycle_epochs_decay=2, lr_decay_factor=0.5):\n",
    "    epoch_in_cycle = epoch % num_epochs_per_cycle\n",
    "    lr = init_lr * (lr_decay_factor ** (epoch_in_cycle // cycle_epochs_decay))\n",
    "    return lr\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, lr 0.0001:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold is 4\n",
      "hello\n",
      "learning rate is  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/6666/rajat.modi/anaconda3/envs/gpuenv/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Epoch 1, lr 0.0001: 100%|██████████| 4080/4080 [15:31<00:00,  4.48it/s, loss=0.01346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:33<00:00,  6.78it/s]\n",
      "Epoch 2, lr 5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.01784, dice: 0.99325\n",
      "better_val_loss model found 0.017843000158401474\n",
      "learning rate is  5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, lr 5e-05: 100%|██████████| 4080/4080 [15:20<00:00,  4.46it/s, loss=0.00930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:20<00:00,  7.77it/s]\n",
      "Epoch 3, lr 5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.01181, dice: 0.99542\n",
      "better_val_loss model found 0.011814167288812025\n",
      "learning rate is  5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, lr 5e-05: 100%|██████████| 4080/4080 [15:16<00:00,  4.48it/s, loss=0.00755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:19<00:00,  7.18it/s]\n",
      "Epoch 4, lr 2.5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00997, dice: 0.99609\n",
      "better_val_loss model found 0.009971092931837552\n",
      "learning rate is  2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, lr 2.5e-05: 100%|██████████| 4080/4080 [15:18<00:00,  4.47it/s, loss=0.00709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:37<00:00,  6.33it/s]\n",
      "Epoch 5, lr 0.0001:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00899, dice: 0.99639\n",
      "better_val_loss model found 0.00898582278935623\n",
      "learning rate is  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, lr 0.0001: 100%|██████████| 4080/4080 [15:15<00:00,  4.48it/s, loss=0.00759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:23<00:00,  7.39it/s]\n",
      "Epoch 6, lr 0.0001:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00952, dice: 0.99623\n",
      "learning rate is  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, lr 0.0001: 100%|██████████| 4080/4080 [15:17<00:00,  4.48it/s, loss=0.01309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:35<00:00,  6.67it/s]\n",
      "Epoch 7, lr 5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.01725, dice: 0.99395\n",
      "learning rate is  5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, lr 5e-05: 100%|██████████| 4080/4080 [15:17<00:00,  4.48it/s, loss=0.00777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:36<00:00,  6.34it/s]\n",
      "Epoch 8, lr 5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00963, dice: 0.99616\n",
      "learning rate is  5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, lr 5e-05: 100%|██████████| 4080/4080 [15:15<00:00,  4.48it/s, loss=0.00657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:15<00:00,  7.38it/s]\n",
      "Epoch 9, lr 2.5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00815, dice: 0.99666\n",
      "better_val_loss model found 0.008146436576406279\n",
      "learning rate is  2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, lr 2.5e-05: 100%|██████████| 4080/4080 [15:16<00:00,  4.48it/s, loss=0.00627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:22<00:00,  6.85it/s]\n",
      "Epoch 10, lr 0.0001:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00801, dice: 0.99671\n",
      "better_val_loss model found 0.008011562875398094\n",
      "learning rate is  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, lr 0.0001: 100%|██████████| 4080/4080 [15:13<00:00,  4.48it/s, loss=0.00629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:31<00:00,  6.56it/s]\n",
      "Epoch 11, lr 0.0001:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00811, dice: 0.99670\n",
      "learning rate is  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, lr 0.0001: 100%|██████████| 4080/4080 [15:14<00:00,  4.49it/s, loss=0.00618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:09<00:00,  7.30it/s]\n",
      "Epoch 12, lr 5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00808, dice: 0.99671\n",
      "learning rate is  5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, lr 5e-05: 100%|██████████| 4080/4080 [15:16<00:00,  4.47it/s, loss=0.00598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:29<00:00,  7.46it/s]\n",
      "Epoch 13, lr 5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00798, dice: 0.99677\n",
      "better_val_loss model found 0.007981037998217203\n",
      "learning rate is  5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, lr 5e-05: 100%|██████████| 4080/4080 [15:16<00:00,  4.49it/s, loss=0.00577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:17<00:00,  7.18it/s]\n",
      "Epoch 14, lr 2.5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00792, dice: 0.99681\n",
      "better_val_loss model found 0.007915897250530265\n",
      "learning rate is  2.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, lr 2.5e-05: 100%|██████████| 4080/4080 [15:14<00:00,  4.45it/s, loss=0.00577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:40<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00764, dice: 0.99689\n",
      "better_val_loss model found 0.007644008529106421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, lr 0.0001:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, lr 0.0001: 100%|██████████| 4080/4080 [15:14<00:00,  4.48it/s, loss=0.00557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:22<00:00,  6.61it/s]\n",
      "Epoch 16, lr 0.0001:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00786, dice: 0.99685\n",
      "learning rate is  0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, lr 0.0001: 100%|██████████| 4080/4080 [15:14<00:00,  4.48it/s, loss=0.00642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:35<00:00,  6.27it/s]\n",
      "Epoch 17, lr 5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00944, dice: 0.99637\n",
      "learning rate is  5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, lr 5e-05: 100%|██████████| 4080/4080 [15:13<00:00,  4.47it/s, loss=0.00566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [02:23<00:00,  6.69it/s]\n",
      "Epoch 18, lr 5e-05:   0%|          | 0/4080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.00802, dice: 0.99676\n",
      "learning rate is  5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, lr 5e-05:  53%|█████▎    | 2160/4080 [08:03<07:13,  4.42it/s, loss=0.00745]"
     ]
    }
   ],
   "source": [
    "#for each fold, load its train and val sets\n",
    "for fold_no in range(4,5):\n",
    "    \n",
    "    print(\"initializing the model\",)\n",
    "    #create the model \n",
    "    model=UNet11().to(device)\n",
    "    criterion=Loss() \n",
    "    model=nn.DataParallel(model,device_ids=[1,2])\n",
    "    print(\"fold is\",fold_no) \n",
    "    train_loader=make_loader(local_data_path/str(fold_no)/'train')\n",
    "    val_loader=make_loader(local_data_path/str(fold_no)/'val')\n",
    "\n",
    "    #####################SAVE MODEL PATH BEGINS#################\n",
    "    model_save_path=Path('.').absolute()/'modelweights'\n",
    "    model_save_path.mkdir(exist_ok=True, parents=True)\n",
    "    best_model_save_path=Path('.').absolute()/'bestmodelweights'\n",
    "    best_model_save_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    model_fold='model_{fold}.pt'.format(fold=fold_no)\n",
    "    save =lambda ep:torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'epoch': ep,\n",
    "            'best_valid_loss': best_valid_loss\n",
    "        }, str(model_save_path/str(model_fold)))\n",
    "    ###################MODEL SAVE ENDS#######################\n",
    "    #################TRAINING FUNCTION########################\n",
    "    print('hello')\n",
    "    batch_size=4\n",
    "    n_epochs=20\n",
    "    lr= 0.0001\n",
    "    report_loss_threshold=10\n",
    "    optimizer= Adam(model.parameters(),lr=lr)\n",
    "    #criterion=loss\n",
    "    best_valid_loss = float('inf')\n",
    "    valid_losses=[]\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        lr=cyclic_lr(epoch)\n",
    "        print(\"learning rate is \",lr)\n",
    "        optimizer=Adam(model.parameters(),lr=lr)\n",
    "        model.train()\n",
    "        #define the progressbar here\n",
    "        tq=tqdm(total=len(train_loader)*batch_size)\n",
    "        tq.set_description('Epoch {}, lr {}'.format(epoch, lr))\n",
    "        losses=[]\n",
    "        #main training loop comes here\n",
    "\n",
    "        for i,(inputs,target) in enumerate(train_loader):\n",
    "            #inputs=inputs.to(device)\n",
    "            target=target.to(device)\n",
    "            #print(inputs.size)\n",
    "            output=model(inputs).to(device)\n",
    "            #print(output.size())\n",
    "            loss=criterion(output,target)\n",
    "            optimizer.zero_grad()\n",
    "            current_batch_size=inputs.size(0)\n",
    "            tq.update(current_batch_size)\n",
    "            #print(loss.item())\n",
    "            losses.append(loss.item())\n",
    "            mean_loss=np.mean(losses[-report_loss_threshold:])\n",
    "            #set the postfix of the progress bar \n",
    "            tq.set_postfix(loss='{:.5f}'.format(mean_loss))\n",
    "            (current_batch_size*loss).backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #close the progress bar \n",
    "        tq.close()\n",
    "        print(\"saving model epoch\",epoch)\n",
    "        save(epoch)\n",
    "        valid_metrics=validation(model,criterion,val_loader)\n",
    "        valid_loss=valid_metrics['valid_loss']\n",
    "        valid_losses.append(valid_loss)\n",
    "        #check if the val loss is less than the best loss\n",
    "        if valid_loss<best_valid_loss:\n",
    "            print(\"better_val_loss model found\",valid_loss)\n",
    "            best_valid_loss=valid_loss\n",
    "            #copy the model to the best_model_loss directory\n",
    "            shutil.copy(str(model_save_path/str(model_fold)),str(best_model_save_path/str(model_fold)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################PREDICTION LOOP##############################\n",
    "#writing the code for prediction\n",
    "#rewrite the dataloader for test dataset, since no masks are present \n",
    "#we will predict the masks for val and test_hq for each fold\n",
    "\n",
    "img_transform = Compose([\n",
    "    ToTensor(),dataset=PredictionDatasetPure(from_path),\n",
    "            shuffle=False,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=1,\n",
    "            pin_memory=True\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "def load_image(path):\n",
    "    img=cv2.imread(path)\n",
    "    img = cv2.copyMakeBorder(img, 0, 0, 1, 1, cv2.BORDER_REFLECT_101)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #img=cv2.resize(img,(img.shape[1]//2,img.shape[0]//2))\n",
    "    return img.astype(np.uint8)\n",
    "#dataset to load the prediction images\n",
    "class PredictionDatasetPure:\n",
    "    def __init__(self, paths):\n",
    "        self.paths = paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx % len(self.paths)]\n",
    "        print(path)\n",
    "        image = load_image(str(path))\n",
    "        #path.stem returns the path \n",
    "        return img_transform(image),path.stem\n",
    "    \n",
    "###################WE PREDICT HERE###################################################    \n",
    "#function to take a from path, to path & to paste the predictions\n",
    "\n",
    "def predict(model, from_paths, batch_size: int, to_path):\n",
    "    loader = DataLoader(\n",
    "        dataset=PredictionDatasetPure(from_paths),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=1,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    for batch_num, (inputs) in enumerate(tqdm(loader, desc='Predict')):\n",
    "        inputs = utils.variable(inputs, volatile=True)\n",
    "        outputs = model(inputs)\n",
    "        mask = (outputs.data.cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "        for i, image_name in enumerate(stems):\n",
    "            cv2.imwrite(str(to_path / (stems[i] +img_transform '.png')), mask[i, 0, :, 1:-1])\n",
    "\n",
    "batch_size=4\n",
    "           \n",
    "fold_no=4\n",
    "local_data_path=Path('.').absolute()restore the model from here\n",
    "prediction_path=(local_data_path/'predictions').mkdir(exist_ok=True, parents=True)\n",
    "val_images=sorted(list((local_data_path/'folds'/str(fold_no)/'val'/'images').glob('*.jpg')))\n",
    "len_val=len(val_images)\n",
    "test_images=sorted(list((local_data_path/'test_hq').glob('*.jpg')))\n",
    "len_test=len(test_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=PredictionDatasetPure(test_images)\n",
    "_,b=a[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_image(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
